{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPyRYLmvgcEWUC+vNyo831l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nikolaifan24/Palm2-API/blob/main/Probando.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install google-generativeai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "id": "6sXW6PjLtUIz",
        "outputId": "32d2b886-c324-4534-8025-c6ca2560d6cf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-generativeai\n",
            "  Downloading google_generativeai-0.1.0-py3-none-any.whl (122 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/122.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/122.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/122.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-ai-generativelanguage==0.2.0 (from google-generativeai)\n",
            "  Downloading google_ai_generativelanguage-0.2.0-py3-none-any.whl (113 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.3/113.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.2.0->google-generativeai) (2.11.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.2.0->google-generativeai) (1.22.3)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.2.0->google-generativeai) (3.20.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.2.0->google-generativeai) (1.60.0)\n",
            "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.2.0->google-generativeai) (2.17.3)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.2.0->google-generativeai) (2.31.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.2.0->google-generativeai) (1.56.2)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.2.0->google-generativeai) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.2.0->google-generativeai) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.2.0->google-generativeai) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.2.0->google-generativeai) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.2.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.2.0->google-generativeai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.2.0->google-generativeai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.2.0->google-generativeai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.2.0->google-generativeai) (2023.7.22)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.2.0->google-generativeai) (0.5.0)\n",
            "Installing collected packages: google-ai-generativelanguage, google-generativeai\n",
            "Successfully installed google-ai-generativelanguage-0.2.0 google-generativeai-0.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtJgzmGys693",
        "outputId": "935b398b-8f62-4f67-e069-557fdeeee58f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Key points:**\n",
            "\n",
            "- **Meta is releasing LLaMA, a state-of-the-art foundational large language model.**\n",
            "- **LLaMA is smaller and more performant than other large language models, making it more accessible to researchers.**\n",
            "- **LLaMA is trained on a large set of unlabeled data, making it ideal for fine-tuning for a variety of tasks.**\n",
            "- **We are releasing LLaMA under a noncommercial license focused on research use cases.**\n",
            "- **We believe that the entire AI community must work together to develop clear guidelines around responsible AI in general and responsible large language models in particular.**\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "At the command line, only need to run once to install the package via pip:\n",
        "$ pip install google-generativeai\n",
        "\"\"\"\n",
        "\n",
        "import google.generativeai as palm\n",
        "\n",
        "palm.configure(api_key=\"AIzaSyAoH0OqYWd8HpzQmoKvv8LEZKY2xk1aAcY\")\n",
        "\n",
        "defaults = {\n",
        "  'model': 'models/text-bison-001',\n",
        "  'temperature': 0.7,\n",
        "  'candidate_count': 1,\n",
        "  'top_k': 40,\n",
        "  'top_p': 0.95,\n",
        "  'max_output_tokens': 1024,\n",
        "  'stop_sequences': [],\n",
        "  'safety_settings': [{\"category\":\"HARM_CATEGORY_DEROGATORY\",\"threshold\":1},{\"category\":\"HARM_CATEGORY_TOXICITY\",\"threshold\":1},{\"category\":\"HARM_CATEGORY_VIOLENCE\",\"threshold\":2},{\"category\":\"HARM_CATEGORY_SEXUAL\",\"threshold\":2},{\"category\":\"HARM_CATEGORY_MEDICAL\",\"threshold\":2},{\"category\":\"HARM_CATEGORY_DANGEROUS\",\"threshold\":2}],\n",
        "}\n",
        "prompt = f\"\"\"Write a concise summary of the following text delimited by triple backquotes.\n",
        "              Return your response in bullet points which covers the key points of the text.\n",
        "              BULLET POINT SUMMARY:\n",
        "\t\t\t\tAs part of Meta’s commitment to open science, today we are publicly releasing LLaMA (Large Language Model Meta AI), a state-of-the-art foundational large language model designed to help researchers advance their work in this subfield of AI. Smaller, more performant models such as LLaMA enable others in the research community who don’t have access to large amounts of infrastructure to study these models, further democratizing access in this important, fast-changing field.\n",
        "\n",
        "Training smaller foundation models like LLaMA is desirable in the large language model space because it requires far less computing power and resources to test new approaches, validate others’ work, and explore new use cases. Foundation models train on a large set of unlabeled data, which makes them ideal for fine-tuning for a variety of tasks. We are making LLaMA available at several sizes (7B, 13B, 33B, and 65B parameters) and also sharing a LLaMA model card that details how we built the model in keeping with our approach to Responsible AI practices.\n",
        "\n",
        "Over the last year, large language models — natural language processing (NLP) systems with billions of parameters — have shown new capabilities to generate creative text, solve mathematical theorems, predict protein structures, answer reading comprehension questions, and more. They are one of the clearest cases of the substantial potential benefits AI can offer at scale to billions of people.\n",
        "\n",
        "Even with all the recent advancements in large language models, full research access to them remains limited because of the resources that are required to train and run such large models. This restricted access has limited researchers’ ability to understand how and why these large language models work, hindering progress on efforts to improve their robustness and mitigate known issues, such as bias, toxicity, and the potential for generating misinformation.\n",
        "\n",
        "Smaller models trained on more tokens — which are pieces of words — are easier to retrain and fine-tune for specific potential product use cases. We trained LLaMA 65B and LLaMA 33B on 1.4 trillion tokens. Our smallest model, LLaMA 7B, is trained on one trillion tokens.\n",
        "\n",
        "Like other large language models, LLaMA works by taking a sequence of words as an input and predicts a next word to recursively generate text. To train our model, we chose text from the 20 languages with the most speakers, focusing on those with Latin and Cyrillic alphabets.\n",
        "\n",
        "There is still more research that needs to be done to address the risks of bias, toxic comments, and hallucinations in large language models. Like other models, LLaMA shares these challenges. As a foundation model, LLaMA is designed to be versatile and can be applied to many different use cases, versus a fine-tuned model that is designed for a specific task. By sharing the code for LLaMA, other researchers can more easily test new approaches to limiting or eliminating these problems in large language models. We also provide in the paper a set of evaluations on benchmarks evaluating model biases and toxicity to show the model’s limitations and to support further research in this crucial area.\n",
        "\n",
        "To maintain integrity and prevent misuse, we are releasing our model under a noncommercial license focused on research use cases. Access to the model will be granted on a case-by-case basis to academic researchers; those affiliated with organizations in government, civil society, and academia; and industry research laboratories around the world. People interested in applying for access can find the link to the application in our research paper.\n",
        "\n",
        "We believe that the entire AI community — academic researchers, civil society, policymakers, and industry — must work together to develop clear guidelines around responsible AI in general and responsible large language models in particular. We look forward to seeing what the community can learn — and eventually build — using LLaMA.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "response = palm.generate_text(\n",
        "  **defaults,\n",
        "  prompt=prompt\n",
        ")\n",
        "print(response.result)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt1 = f\"\"\"Write a concise summary of the following text delimited by triple backquotes.\n",
        "              Return your response in bullet points which covers the key points of the text.\n",
        "              BULLET POINT SUMMARY:\n",
        "\t\t\t\tTesla, Inc. (/ˈtɛslə/ TESS-lə or /ˈtɛzlə/ TEZ-lə[a]) is an American multinational automotive and clean energy company headquartered in Austin, Texas. Tesla designs and manufactures electric vehicles (cars and trucks), stationary battery energy storage devices from home to grid-scale, solar panels and solar roof tiles, and related products and services.\n",
        "\n",
        "Tesla is one of the world's most valuable companies and, as of 2023, was the world's most valuable automaker. In 2022, the company led the battery electric vehicle market, with 18% share.\n",
        "\n",
        "Its subsidiary Tesla Energy develops and is a major installer of photovoltaic systems in the United States. Tesla Energy is one of the largest global suppliers of battery energy storage systems, with 6.5 gigawatt-hours (GWh) installed in 2022.\n",
        "\n",
        "Tesla was incorporated in July 2003 by Martin Eberhard and Marc Tarpenning as Tesla Motors. The company's name is a tribute to inventor and electrical engineer Nikola Tesla. In February 2004, via a $6.5 million investment, Elon Musk became the company's largest shareholder. He became CEO in 2008. Tesla's announced mission is to help expedite the move to sustainable transport and energy, obtained through electric vehicles and solar power.\n",
        "\n",
        "Tesla began production of its first car model, the Roadster sports car, in 2008. This was followed by the Model S sedan in 2012, the Model X SUV in 2015, the Model 3 sedan in 2017, the Model Y crossover in 2020, and the Tesla Semi truck in 2022. The company plans production of the Cybertruck light-duty pickup truck in 2023.[8] The Model 3 is the all-time bestselling plug-in electric car worldwide, and in June 2021 became the first electric car to sell 1 million units globally.[9] Tesla's 2022 deliveries were around 1.31 million vehicles, a 40% increase over the previous year,[10][11] and cumulative sales totaled 4 million cars as of April 2023.[12] In October 2021, Tesla's market capitalization temporarily reached $1 trillion, the sixth company to do so in U.S. history.\n",
        "\n",
        "Tesla has been the subject of lawsuits, government scrutiny, and journalistic criticism, stemming from allegations of whistleblower retaliation, worker rights violations, product defects, and Musk's many controversial statements.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "sQ2hrMn4up-V"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = palm.generate_text(\n",
        "  **defaults,\n",
        "  prompt=prompt1\n",
        ")\n",
        "print(response.result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MB9zb0KQtVYi",
        "outputId": "2b9f23f3-2e9b-45d4-9de7-0750d1ace058"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Tesla is an American multinational automotive and clean energy company.\n",
            "- Tesla designs and manufactures electric vehicles, stationary battery energy storage devices, solar panels and solar roof tiles.\n",
            "- Tesla is one of the world's most valuable companies and, as of 2023, was the world's most valuable automaker.\n",
            "- Tesla was founded in 2003 by Martin Eberhard and Marc Tarpenning.\n",
            "- Tesla's mission is to help expedite the move to sustainable transport and energy, obtained through electric vehicles and solar power.\n",
            "- Tesla has been the subject of lawsuits, government scrutiny, and journalistic criticism, stemming from allegations of whistleblower retaliation, worker rights violations, product defects, and Musk's many controversial statements.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt2 = f\"\"\"Please analyze the following text for grammar mistakes and highlight the location of each mistake:\n",
        "It? Yeah. You practiced? I participate in participated. Participated in five meetings.\n",
        " You're all about meetings. Okay. Five meetings. Okay, good. So your whole day was up meetings, or you\n",
        " also had to work apart from these meetings? Sorry? Your whole day was meetings, or you also had to work\n",
        "  apart from the meetings? I don't understand. Okay, so you understand this word, paul? Paul is paul is\n",
        "  like complete. Okay, so my question is, was your whole day your complete day was just meetings, or you\n",
        "  also had to work on your computer? Okay, in some meetings I could work, yes. Okay, good. So for example,\n",
        "  for whole, we say whole milk. Milk. We say whole milk. Whole milk? Yeah. Do you drink whole milk or you\n",
        "  like the one lactose free? No, I like drink milk. But whole milk or lactose free? Whole milk. Yeah, no problem.\n",
        "   Yeah. Okay. Your enzymes work very well. Enzymes? Yeah. Okay, awesome. Great. So for today, as I told you, we're\n",
        "   going to have a class of a business class. We have some business classes. We're going to mix with the program, okay?\n",
        "   And this is one that's really important, is the class number two from the document you're going to find in your folder\n",
        "   It's called describing tendencies and projections. Okay? We need this for everything. Okay? For example, when you have\n",
        "   a business review, we need to say, what happened? How was it? Right. What was the tendency on this month, on this semester,\n",
        "   on this year, and what's going to happen in the future? Right? So that's what we need, tendencies and projections. Okay,\n",
        "   we're going to start with the first tendency, which is this one go up. Okay, this is the first one go up. So for going up\n",
        "   in How I Met Your mother. Have you ever seen How I Met your Mother? The show. You know the show? How I met your mother. It's a show.\n",
        "   It's a series. You know this one meet I don't remember meat. This is a series. How much your mother is in a city? No. Okay.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "GCbhv4TlxMyT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = palm.generate_text(\n",
        "  **defaults,\n",
        "  prompt=prompt2\n",
        ")\n",
        "print(response.result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmNATCn8ypZm",
        "outputId": "2c118b24-3ad0-40a5-ad93-b9115762b720"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Errors:**\n",
            "\n",
            "1. \"It?\" should be \"Did you?\"\n",
            "2. \"participated in participated\" should be \"participated in\"\n",
            "3. \"Five meetings. Okay. Good. So your whole day was up meetings, or you\" should be \"Five meetings. Okay. Good. So your whole day was meetings, or you\"\n",
            "4. \"Sorry? Your whole day was meetings, or you also had to work apart from the meetings? I don't understand. Okay, so you understand this word, paul? Paul is paul is\" should be \"Sorry? Your whole day was meetings, or you also had to work apart from the meetings? I don't understand. Okay, so you understand this word, whole? Whole is whole is\"\n",
            "5. \"Okay, in some meetings I could work, yes. Okay, good. So for example, for whole, we say whole milk. Milk. We say whole milk. Whole milk? Yeah. Do you drink whole milk or you like the one lactose free? No, I like drink milk. But whole milk or lactose free? Whole milk. Yeah, no problem. Yeah. Okay. Your enzymes work very well. Enzymes? Yeah. Okay, awesome. Great. So for today, as I told you, we're\" should be \"Okay, in some meetings I could work, yes. Okay, good. So for example, for whole, we say whole milk. Milk. We say whole milk. Whole milk? Yeah. Do you drink whole milk or do you like the lactose-free one? No, I like drinking milk. But whole milk or lactose-free? Whole milk. Yeah, no problem. Yeah. Okay. Your enzymes work very well. Enzymes? Yeah. Okay, awesome. Great. So for today, as I told you, we're\"\n",
            "6. \"going to have a class of a business class. We have some business classes. We're going to mix with the program, okay?\" should be \"going to have a business class. We have some business classes. We're going to integrate with the program, okay?\"\n",
            "7. \"It's called describing tendencies and projections. Okay? We need this for everything. Okay? For example, when you have a business review, we need to say, what happened? How was it? Right. What was the tendency on this month, on this semester, on this year, and what's going to happen in the future? Right? So that's what we need, tendencies and projections. Okay, we're going to start with the first tendency, which is this one go up. Okay, this is the first one go up. So for going up in How I Met Your mother. Have you ever seen How I Met your Mother? The show. You know the show?\" should be \"It's called describing tendencies and projections. Okay? We need this for everything. Okay? For example, when you have a business review, we need to say, what happened? How was it? Right. What was the tendency this month, this semester, this year, and what's going to happen in the future? Right? So that's what we need, tendencies and projections. Okay, we're going to start with the first tendency, which is this one going up. Okay, this is the first one going up. So for going up in How I Met Your Mother. Have you ever seen How I Met Your Mother? The show? You know the show?\"\n",
            "8. \"How much your mother is in a city? No. Okay.\" should be \"How much your mother is in a city? No.\"\n"
          ]
        }
      ]
    }
  ]
}